# -*- coding: utf-8 -*-
"""Phase_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-uBteS_UeBn5GtqCZfM52q78QLj9c0B6
"""

# ============================================================
# PHASE 3 – Optimization, Scaling & Final Evaluation
# Based on Phase 2 Implementations: Trie, Min Heap, Hash Table
# Author: Banoj Kumar Jena (Adapted for Optimization Phase)
# ============================================================

import time
import random
import string
import tracemalloc
import matplotlib.pyplot as plt


# ============================================================
# 1. PHASE 2 IMPLEMENTATIONS (Baseline)
# ============================================================

class TrieNode:
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False


class Trie:
    def __init__(self):
        self.root = TrieNode()

    def insert(self, word):
        node = self.root
        for char in word:
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.is_end_of_word = True

    def search(self, word):
        node = self.root
        for char in word:
            if char not in node.children:
                return False
            node = node.children[char]
        return node.is_end_of_word


class MinHeap:
    def __init__(self):
        self.heap = []

    def _parent(self, index): return (index - 1) // 2
    def _left(self, index): return 2 * index + 1
    def _right(self, index): return 2 * index + 2

    def insert(self, value):
        self.heap.append(value)
        self._heapify_up(len(self.heap) - 1)

    def _heapify_up(self, index):
        while index > 0:
            parent = self._parent(index)
            if self.heap[index] < self.heap[parent]:
                self.heap[index], self.heap[parent] = self.heap[parent], self.heap[index]
                index = parent
            else:
                break

    def extract_min(self):
        if not self.heap: return None
        if len(self.heap) == 1: return self.heap.pop()

        root = self.heap[0]
        self.heap[0] = self.heap.pop()
        self._heapify_down(0)
        return root

    def _heapify_down(self, index):
        smallest = index
        left, right = self._left(index), self._right(index)

        if left < len(self.heap) and self.heap[left] < self.heap[smallest]:
            smallest = left
        if right < len(self.heap) and self.heap[right] < self.heap[smallest]:
            smallest = right

        if smallest != index:
            self.heap[index], self.heap[smallest] = self.heap[smallest], self.heap[index]
            self._heapify_down(smallest)


class HashTable:
    def __init__(self, size=10):
        self.size = size
        self.table = [[] for _ in range(size)]

    def _hash(self, key):
        return hash(key) % self.size

    def insert(self, key, value):
        idx = self._hash(key)
        for i, (k, v) in enumerate(self.table[idx]):
            if k == key:
                self.table[idx][i] = (key, value)
                return
        self.table[idx].append((key, value))

    def search(self, key):
        idx = self._hash(key)
        for k, v in self.table[idx]:
            if k == key:
                return v
        return None

    def delete(self, key):
        idx = self._hash(key)
        for i, (k, v) in enumerate(self.table[idx]):
            if k == key:
                del self.table[idx][i]
                return True
        return False


# ============================================================
# 2. OPTIMIZED VERSIONS FOR PHASE 3
# ============================================================

# ---- Trie Optimization: Using __slots__ for memory + caching ----
class FastTrieNode:
    __slots__ = ("children", "is_end_of_word")
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False


class FastTrie:
    def __init__(self):
        self.root = FastTrieNode()

    def insert(self, word):
        node = self.root
        for char in word:
            node = node.children.setdefault(char, FastTrieNode())
        node.is_end_of_word = True

    def search(self, word):
        node = self.root
        for char in word:
            node = node.children.get(char)
            if not node:
                return False
        return node.is_end_of_word


# ---- MinHeap Optimization: Bulk heapify (O(n)) instead of O(n log n) insert ----
class FastMinHeap:
    def __init__(self):
        self.heap = []

    def build_heap(self, arr):
        """Optimized heap construction from array."""
        self.heap = arr[:]
        for i in range(len(self.heap)//2, -1, -1):
            self._heapify_down(i)

    def _parent(self, index): return (index - 1) // 2
    def _left(self, index): return 2 * index + 1
    def _right(self, index): return 2 * index + 2

    def insert(self, value):
        self.heap.append(value)
        self._heapify_up(len(self.heap)-1)

    def _heapify_up(self, index):
        while index > 0:
            parent = self._parent(index)
            if self.heap[index] < self.heap[parent]:
                self.heap[index], self.heap[parent] = self.heap[parent], self.heap[index]
                index = parent
            else:
                break

    def extract_min(self):
        if not self.heap: return None
        if len(self.heap) == 1: return self.heap.pop()
        root = self.heap[0]
        self.heap[0] = self.heap.pop()
        self._heapify_down(0)
        return root

    def _heapify_down(self, index):
        smallest = index
        left, right = self._left(index), self._right(index)

        if left < len(self.heap) and self.heap[left] < self.heap[smallest]:
            smallest = left
        if right < len(self.heap) and self.heap[right] < self.heap[smallest]:
            smallest = right

        if smallest != index:
            self.heap[index], self.heap[smallest] = self.heap[smallest], self.heap[index]
            self._heapify_down(smallest)


# ---- HashTable Optimization: Dynamic resizing + better hashing ----
class FastHashTable:
    def __init__(self, size=16):
        self.size = size
        self.count = 0
        self.table = [[] for _ in range(size)]

    def _hash(self, key):
        return (hash(key) ^ (hash(key) >> 16)) % self.size

    def _resize(self):
        if self.count / self.size > 0.7:
            self.size *= 2
            old = self.table
            self.table = [[] for _ in range(self.size)]
            for bucket in old:
                for key, value in bucket:
                    self.insert(key, value)

    def insert(self, key, value):
        self._resize()
        idx = self._hash(key)
        for i, (k, v) in enumerate(self.table[idx]):
            if k == key:
                self.table[idx][i] = (key, value)
                return
        self.table[idx].append((key, value))
        self.count += 1

    def search(self, key):
        idx = self._hash(key)
        for k, v in self.table[idx]:
            if k == key:
                return v
        return None


# ============================================================
# 3. PERFORMANCE FUNCTIONS
# ============================================================

def measure_time(func, *args):
    start = time.perf_counter()
    result = func(*args)
    end = time.perf_counter()
    return end - start, result


def measure_memory(func, *args):
    tracemalloc.start()
    result = func(*args)
    curr, peak = tracemalloc.get_traced_memory()
    tracemalloc.stop()
    return peak / 1024**2, result   # return in MB


# ============================================================
# 4. DATA GENERATION FOR STRESS TESTING
# ============================================================

def random_words(n, length=6):
    return [
        ''.join(random.choices(string.ascii_lowercase, k=length))
        for _ in range(n)
    ]


# ============================================================
# 5. SCALABILITY TESTING
# ============================================================

sizes = [1_000, 5_000, 20_000, 50_000, 100_000]

baseline_trie_time = []
optimized_trie_time = []

for size in sizes:
    words = random_words(size)

    # Baseline
    trie = Trie()
    t, _ = measure_time(lambda: [trie.insert(w) for w in words])
    baseline_trie_time.append(t)

    # Optimized FastTrie
    fast_trie = FastTrie()
    t, _ = measure_time(lambda: [fast_trie.insert(w) for w in words])
    optimized_trie_time.append(t)

    print(f"Inserted {size} words: Baseline={baseline_trie_time[-1]:.4f}s, Optimized={optimized_trie_time[-1]:.4f}s")


# ============================================================
# 6. PERFORMANCE PLOTS
# ============================================================

plt.plot(sizes, baseline_trie_time, label="Baseline Trie")
plt.plot(sizes, optimized_trie_time, label="Optimized Trie")
plt.xlabel("Dataset Size")
plt.ylabel("Insert Time (seconds)")
plt.title("Trie Performance Comparison")
plt.legend()
plt.grid(True)
plt.show()


# ============================================================
# 7. VALIDATION TESTS
# ============================================================

def validate(label, structure):
    print(f"\nValidation – {label}")
    structure.insert("apple")
    structure.insert("banana")
    structure.insert("bat")
    print("Search apple:", structure.search("apple"))
    print("Search banana:", structure.search("banana"))
    print("Search bat:", structure.search("bat"))
    print("Search ghost:", structure.search("ghost"))

validate("Baseline Trie", Trie())
validate("Optimized Trie", FastTrie())

print("\n=== PHASE 3 EXECUTION COMPLETE ===")

